{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFUSION MATRIX  ::\n",
    "\n",
    "As we noticed in the previous part, we care not only about how many datapoints we predict the correct class for, we care about how many of the positive datapoints we predict correctly for as well as how many of the negative datapoints we predict correctly.\n",
    "\n",
    "We can see all the important values in what is called the Confusion Matrix (or Error Matrix or Table of Confusion).\n",
    "\n",
    "The Confusion Matrix is a table showing four values:\n",
    "\n",
    "     • Datapoints we predicted positive that are actually positive\n",
    "     • Datapoints we predicted positive that are actually negative\n",
    "     • Datapoints we predicted negative that are actually positive\n",
    "     • Datapoints we predicted negative that are actually negative\n",
    "     \n",
    "The first and fourth are the datapoints we predicted correctly and the second and third are the datapoints we predicted incorrectly.\n",
    "\n",
    "The confusion matrix fully describes how a model performs on a dataset, though is difficult to use to compare models.\n",
    "\n",
    "\n",
    "\n",
    "TRUE POSITIVE, TRUE NEGATIVE, FALSE POSITIVE, FALSE NEGATIVE  ::\n",
    "\n",
    "We have names for each square of the confusion matrix:\n",
    "\n",
    "     A true positive (TP) is a datapoint we predicted positively that we were correct about.\n",
    "     A true negative (TN) is a datapoint we predicted negatively that we were correct about.\n",
    "     A false positive (FP) is a datapoint we predicted positively that we were incorrect about.\n",
    "     A false negative (FN) is a datapoint we predicted negatively that we were incorrect about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision refers to the percentage of positive results which are relevant \n",
    "\n",
    "    Precision is the percent of the model’s positive predictions that are correct.\n",
    "    \n",
    "    precision  = positives predicted correctly / positive predictions\n",
    "               \n",
    "               = TP / (TP + FP)\n",
    "\n",
    "Recall to the percentage of positive cases correctly classified.\n",
    "\n",
    "     Recall = positives predicted correctly / positive cases \n",
    "            \n",
    "            = TP / (TP + FN)\n",
    "            \n",
    "We often will be in a situation of choosing between increasing the recall (while lowering the precision) or \n",
    "\n",
    "increasing the precision (and lowering the recall). It will depend on the situation which we’ll want to maximize.\n",
    "\n",
    "For example, let’s say we’re building a model to predict if a credit card charge is fraudulent. The positive cases for our model are fraudulent charges and the negative cases are legitimate charges.\n",
    "\n",
    "Let’s consider two scenarios:\n",
    "1. If we predict the charge is fraudulent, we’ll reject the charge.\n",
    "2. If we predict the charge is fraudulent, we’ll call the customer to confirm the charge.\n",
    "\n",
    "In case 1, it’s a huge inconvenience for the customer when the model predicts fraud incorrectly (a false positive).\n",
    "\n",
    "In case 2, a false positive is a minor inconvenience for the customer.\n",
    "               \n",
    "The higher the false positives, the lower the precision. Because of the high cost to false positives in the first case, it would be worth having a low recall in order to have a very high precision. In case 2, you would want more of a balance between precision and recall.\n",
    "\n",
    "There is often a trade-off between precision and recall. Increasing the model's precision means making the model less sensitive, to lower the false positive rate. But a less sensitive model could also miss more actual positives, leading to a lower recall. Increasing the model's recall means making the model more sensitive, to lower the false negative rate. But a more sensitive model could also incorrectly flag more false positives, leading to lower precision.\n",
    "\n",
    "CASE SCENARIO ::\n",
    "We’re building a model to predict spam email. The positive cases are spam and the negative cases are legitimate. If we’re going to delete email that we predict is spam, which is more important to maximize?\n",
    "\n",
    "      It is important to maximize the preciseness ( by increasing precision) in this case; Since the False Positives will \n",
    "      get DELETED ( emails that are not spam but our model predicts as spam) so an important email might get deleted, due\n",
    "      to a wrong prediction. Here FP are costing us a lot. So we'd better minimize them. (By increasing precision)\n",
    "      \n",
    "      It well known that spam emails are very less as compared to legitimate (important) emails. Precision=TP/(TP+FP)   \n",
    "      Recall=TP/(TP+FN) FP>FN (TP+FP)>(TP+FN) ∴ Precision<Recall It is important to maximize the preciseness ( by increasing \n",
    "      precision) Because .with.. FalsePositives(emails) legitimate(important) emails will also be \"\"\"deleted \"\"\", due to a\n",
    "      wrong prediction. FP is costing more than FN WE HAVE TO MAXIMIZE--Precision=TP/(TP+FP)\n",
    "      \n",
    "      In general given any problem like this and before you pick up your choice between precision and Recall, firstly \n",
    "      determine which you care about minimizing or maximizing of( FP or FN) becaus they affect directly the precision and \n",
    "      Recall. Increase FP will lower precision, decrease it will increase precision. Increase FN will lower Recall, decrease \n",
    "      it will increase Recall. Precision=TP/(TP+FP) Recall=TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy was an appealing metric because it was a single number. Precision and recall are two numbers so it’s not always obvious how to choose between two models if one has a higher precision and the other has a higher recall. The F1 score is an average of precision and recall so that we have a single score for our model.\n",
    "\n",
    "Mathematical formula for the F1 score:\n",
    "\n",
    "      F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "      \n",
    "The F1 score is the harmonic mean of the precision and recall values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Metrics in Scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn has a function built in for each of the metrics(accuracy, precision, recall and F1 score)\n",
    "\n",
    "Each function takes two 1-dimensional numpy arrays: the true values of the target & the predicted values of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses</th>\n",
       "      <th>Parents/Children</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  Siblings/Spouses  Parents/Children     Fare\n",
       "0         0       3    male  22.0                 1                 0   7.2500\n",
       "1         1       1  female  38.0                 1                 0  71.2833\n",
       "2         1       3  female  26.0                 0                 0   7.9250\n",
       "3         1       1  female  35.0                 1                 0  53.1000\n",
       "4         0       3    male  35.0                 0                 0   8.0500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the titanic dataset\n",
    "\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses</th>\n",
       "      <th>Parents/Children</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  Siblings/Spouses  Parents/Children  \\\n",
       "0         0       3    male  22.0                 1                 0   \n",
       "1         1       1  female  38.0                 1                 0   \n",
       "2         1       3  female  26.0                 0                 0   \n",
       "3         1       1  female  35.0                 1                 0   \n",
       "4         0       3    male  35.0                 0                 0   \n",
       "\n",
       "      Fare   Male  \n",
       "0   7.2500   True  \n",
       "1  71.2833  False  \n",
       "2   7.9250  False  \n",
       "3  53.1000  False  \n",
       "4   8.0500   True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing the Sex column to boolean values \n",
    "\n",
    "titanic['Male'] = titanic['Sex'] == 'male'\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting a logistic regression model to titanic  dataset\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "X = titanic[['Pclass', 'Male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare' ]]\n",
    "Y = titanic['Survived']\n",
    "\n",
    "model.fit(X,Y)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8049605411499436\n",
      "precision: 0.7734627831715211\n",
      "recall: 0.6988304093567251\n",
      "f1 score: 0.7342549923195083\n"
     ]
    }
   ],
   "source": [
    "# Calculating the metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"accuracy:\", accuracy_score(Y, y_pred))\n",
    "print(\"precision:\", precision_score(Y, y_pred))\n",
    "print(\"recall:\", recall_score(Y, y_pred))\n",
    "print(\"f1 score:\", f1_score(Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy is 80% which means that 80% of the model’s predictions are correct. \n",
    "\n",
    "The precision is 78%, that is the percent of the model’s positive predictions that are correct. \n",
    "\n",
    "The recall is 68%, which is the percent of the positive cases that the model predicted correctly. \n",
    "\n",
    "The F1 score is 73%, which is an average of the precision and recall.\n",
    "\n",
    "With a single model, the metric values do not tell us a lot. For some problems a value of 60% is good, and for others a value of 90% is good, depending on the difficulty of the problem. We will use the metric values to compare different models to pick the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix in Sklearn\n",
    "\n",
    "Scikit-learn has a confusion matrix function that we can use to get the four values in the confusion matrix (true positives, false positives, false negatives, and true negatives). Assuming y is our true target values and y_pred is the predicted values,\n",
    "\n",
    "we can use the confusion_matrix function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[475  70]\n",
      " [103 239]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn reverses the confusion matrix to show the negative counts first! Here is how this confusion matrix should be labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion Matrix in scikit-learn\n",
    "    \n",
    "                   PN    PP   \n",
    "actual negative............(TN) ... (FP)   ... [[475  70]\n",
    "\n",
    "actual positive.............(FN) ... (TP)  ...   [103 239]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Normally;\n",
    "            \n",
    "                     AP   AN\n",
    "predicted positive ..........(TP).. (FP)..[[239 70]]\n",
    "\n",
    "predicted negative .........(FN).. (TN)..[[103 475]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build an ROC Curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve is a graph of the specificity vs the sensitivity. We build a Logistic Regression model and then calculate the specificity and sensitivity for every possible threshold. Every predicted probability is a threshold. If we have 5 datapoints with the following predicted probabilities: 0.3, 0.4, 0.6, 0.7, 0.8, we would use each of those 5 values as a threshold.\n",
    "\n",
    "Note that we actually plot the sensitivity vs (1-specificity). There is no strong reason for doing it this way besides that it’s the standard.\n",
    "\n",
    "Let’s start by looking at the code to build the ROC curve. Scikit-learn has a roc_curve function we can use. The function takes the true target values and the predicted probabilities from our model.\n",
    "\n",
    "We first use the predict_proba method on the model to get the probabilities. Then we call the roc_curve function. The roc_curve function returns an array of the false positive rates, an array of the true positive rates and the thresholds. The false positive rate is 1-specificity (x-axis) and the true positive rate is another term for the sensitivity (y-axis). The threshold values won’t be needed in the graph.\n",
    "\n",
    "Code for plotting the ROC curve in matplotlib and code for plotting a diagonal line, this can help us visually see how far our model is from a model that predicts randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\n",
    "model1.fit(X_train, Y_train)\n",
    "y_pred_proba1 = model1.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_pred_proba[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle = '--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.xlabel('1 - specificty')\n",
    "plt.ylabel('sensitivity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP - Real positive predicted positive (correct) \n",
    "\n",
    "TN - Real negative predicted negative (correct) \n",
    "\n",
    "FP - Real negative predicted positive (incorrect) \n",
    "\n",
    "FN - Real positive predicted negative (incorrect) \n",
    "\n",
    "Specificity is the % of all real negatives that were  predicted correctly: TN/(TN+FP). Also called the True Negative Rate\n",
    "\n",
    "Corrolary: (1 - Specificity) = FP/(TN+FP). Also called the False Positive Rate (or False Alarm Rate)  \"fpr\"\n",
    "\n",
    "Sensitivity is the % of all real positives that were predicted correctly: TP/(TP+FN). Also called the True Positive Rate \"tpr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve is showing the performance, not of a single model, but of many models. Each choice of threshold is a different model.\n",
    "\n",
    "Assuming we have points A, B, C highlighted at specific regions\n",
    "\n",
    "Each point A, B & C refers to a model with a different threshold.\n",
    "\n",
    "comparing to the graph:\n",
    "Model A has a sensitivity of 0.6 and a specificity of 0.9 (recall that the graph is showing 1-specificity).\n",
    "Model B has a sensitivity of 0.8 and a specificity of 0.7.\n",
    "Model C has a sensitivity of 0.9 and a specificity of 0.5.\n",
    "\n",
    "How to choose between these models will depend on the specifics of our situation.\n",
    "The closer the curve gets to the upper left corner, the better the performance. The line should never fall below the diagonal line as that would mean it performs worse than a random model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking a Model from the ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we’re ready to finalize our model, we have to choose a single threshold that we’ll use to make our predictions. The ROC curve is a way of helping us choose the ideal threshold for our problem\n",
    "\n",
    "looking at our ROC curve again assuming the three highlighted points\n",
    "\n",
    "If we are in a situation where it’s more important that all of our positive predictions are correct than that we catch all the positive cases (meaning that we predict most of the negative cases correctly), we should choose the model with higher specificity (model A).\n",
    "\n",
    "If we are in a situation where it’s important that we catch as many of the positive cases as possible, we should choose the model with the higher sensitivity (model C).\n",
    "\n",
    "If we want a balance between sensitivity and specificity, we should choose model B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area Under the Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll sometimes what to use the ROC curve to compare two different models. \n",
    "\n",
    "Area Under the Curve, also called the AUC. This is the area under the ROC curve. It’s a value between 0 and 1, the higher the better.\n",
    "\n",
    "ROC is a graph of all the different Logistic Regression models with different thresholds, the AUC does not measure the performance of a single model. It gives a general sense of how well the Logistic Regression model is performing. To get a single model, you still need to find the optimal threshold for your problem.\n",
    "\n",
    "Using scikit-learn we can calculate the area under the curve, through the roc_auc_score function.\n",
    "\n",
    "\n",
    "Here is a comparison of the ROC curves of two models:\n",
    "\n",
    "    We will use the roc_auc_score function to calculate the AUC score of a Logistic Regression model on the Titanic dataset.\n",
    "    We will build two Logistic Regression models, model with 6 features and a model with just Pclass and male features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 AUC score: 0.8304526748971194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"model 1 AUC score:\", roc_auc_score(Y_test, y_pred_proba1[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 AUC score: 0.8340094062316284\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "\n",
    "X1 = titanic[['Pclass', 'Male' ]]\n",
    "Y1 = titanic['Survived']\n",
    "\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y1, test_size = 0.3, random_state = 1)\n",
    "model2.fit(X1_train, Y1_train)\n",
    "y_pred_proba2 = model2.predict_proba(X1_test)\n",
    "\n",
    "print(\"model 2 AUC score:\", roc_auc_score(Y1_test, y_pred_proba2[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metric tells us how well in general a Logistic Regression model performs on our data. As an ROC curve shows the performance of multiple models, the AUC is not measuring the performance of a single model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCERNS WITH THE TRAINING AND  TEST SET: \n",
    "\n",
    "We are doing evaluation because we want to get an accurate measure of how well the model performs. If our dataset is small, our test set is going to be small. Thus it might not be a good random assortment of datapoints and by random chance end up with easy or difficult datapoints in our evaluation set.\n",
    "\n",
    "Since our goal is to get the best possible measure of our metrics (accuracy, precision, recall and F1 score), we can do a little better than just a single training and test set.\n",
    "\n",
    "Training Set is used to build the model while the Test Set is used to evaluate the model\n",
    "\n",
    "To see this empirically, we try running the prev code which does a train/test split. We’ll re-run it a few times and see the results.\n",
    "\n",
    "It is seen that each time we run it, we get different values for the metrics. The accuracy ranges from 0.79 to 0.84, the precision from 0.75 to 0.81 and the recall from 0.63 to 0.75. These are wide ranges that just depend on how lucky or unlucky we were in which datapoints ended up in the test set.\n",
    "\n",
    "Instead of doing a single train/test split, we’ll split our data into a training set and test set multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get different values for the evaluation metrics. We want to get a measure of how well our model does in general, not just a measure of how well it does on one specific test set.\n",
    "\n",
    "Instead of just taking a chunk of the data as the test set, let’s break our dataset into 5 chunks. Let’s assume we have 200 datapoints in our dataset.\n",
    "\n",
    "Each of these 5 chunks will serve as a test set. When Chunk 1 is the test set, we use the remaining 4 chunks as the training set. Thus we have 5 training and test sets\n",
    "\n",
    "Each of the 5 times we have a test set of 20% (40 datapoints) and a training set of 80% (160 datapoints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each training set, we build a model and evaluate it using the associated test set. Thus we build 5 models and calculate 5 scores\n",
    "\n",
    "We report the accuracy as the mean of the 5 values:\n",
    "\n",
    "If we had just done a single training and test set and had randomly gotten the first one, we would have reported an accuracy of 0.83. If we had randomly gotten the last one, we would have reported an accuracy of 0.75. Averaging all these possible values helps eliminate the impact of which test set a datapoint lands in.\n",
    "\n",
    "You will only see values this different when you have a small dataset. With large datasets we often just do a training and test set for simplicity.\n",
    "\n",
    "This process for creating multiple training and test sets is called k-fold cross validation. The k is the number of chunks we split our dataset into. The standard number is 5\n",
    "\n",
    "Our goal in cross validation is to get accurate measures for our metrics (accuracy, precision, recall). We are building extra models in order to feel confident in the numbers we calculate and report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Choice in k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we have built 5 models instead of just one. How do we decide on a single model to use?\n",
    "\n",
    "These 5 models were built just for evaluation purposes, so that we can report the metric values. We don’t actually need these models and want to build the best possible model. The best possible model is going to be a model that uses all of the data. So we keep track of our calculated values for our evaluation metrics and then build a model using all of the data.\n",
    "\n",
    "This may seem incredibly wasteful, but computers have a lot of computation power, so it’s worth using a little extra to make sure we’re reporting the right values for our evaluation metrics. We’ll be using these values to make decisions, so calculating them correctly is very important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold Cross Validation in Sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn has already implemented the code to break the dataset into k chunks and create k training and test sets.\n",
    "\n",
    "We start by instantiating a KFold class object. It takes two parameters: n_splits (this is k, the number of chunks to create) and shuffle (whether or not to randomize the order of the data). It’s generally good practice to shuffle the data since you often get a dataset that’s in a sorted order.\n",
    "\n",
    "The KFold class has a split method that creates the 3 splits for our data.\n",
    "\n",
    "Let’s look at the output of the split method. The split method returns a generator, so we use the list function to turn it into a list.\n",
    "\n",
    "     kf = KFold(n_splits=3, shuffle=True)\n",
    "     \n",
    "     list(kf.split(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
